Introduction：
Human Resource Performance Evaluation Model
Abstract: Nowadays, most of the human resource evaluation services are within the enterprise, and college students, as the fresh blood of the society, do not have a human resource evaluation model suitable for themselves. Therefore, it is of great significance to study a human resource model suitable for college students' self-adjustment. The data used in this article is human resource performance data from the Kaggle platform. The evaluation score, number of projects, working hours and work errors are used as independent variables. Three correlation models are established through correlation algorithms, and the importance of independent variables is analyzed. Variables have different degrees of impact on retention, promotion and employee level.
Keywords: human resources; correlation algorithm; importance analysis
1. Problem description
In the practice of human resource management, performance evaluation is a process of measuring and evaluating the performance level of an organization or employee within a predetermined time frame. Performance evaluation has the basic value of human resource management. In the attraction and allocation of employees, the influence and flow of employees, the salary system and the human resources work system, the correlation between the scores of performance evaluation and the results of performance evaluation becomes other human resources The starting point of practice, and determines the use effect of these practical activities.
2. Data description
2.1. Data sources
The data comes from the human resources analysis section of the Kaggle platform https://www.kaggle.com/ludobenistant/hr-analytics. Kaggle is a data science competition platform that mainly provides developers and data scientists with machine learning competitions, hosting databases, writing and sharing codes.
The data set includes 14,999 pieces of data about human resource performance information, each of which includes 10 attributes such as employee level, working hours, number of projects involved, department, salary, and whether there is any mistake. These 10 attributes and their specific meanings are shown in Table 2.1.
Table 2.1 Human Resources Data
Attribute name	Property content
satisfaction_level	from 0 to 1
last_evaluation	from 0 to 1
number_project	from 2 to 7
average_monthly_hours	from 96 to 310
time_spend_company	from 2 to 10
work_accident	0-no
1-yes
left	0-no
1-yes
promotion_last_5years	0-no
1-yes
sales	accounting，hr，IT，management，marketing， product_mng，RandD，sales，support，technical
salary	high，medium，low
2.2. Data preprocessing
Among the 10 attributes in the original data set, working hours and monthly working hours are similar and basically in a linear relationship. Therefore, only the attribute of monthly working hours is selected in the analysis. In addition, the two attributes of department and salary are not applicable to this analysis and are also excluded, so this article will analyze the remaining 7 attributes and perform preprocessing.
3. Algorithm principle
3.1. Principle of Association Algorithm
Association rules are used to mine the correlation between valuable data items from a large amount of data, which is an important topic in the field of data mining. Like the implication formula of X⇒Y, association rules are the discovery of frequent patterns in transactions, itemsets and objects in relational databases, along with process dependencies, correlations and even possible causal structures.
In the field of data mining, Apriori algorithm is a classic algorithm for mining association rules. The Apriori algorithm uses a bottom-up method, starting from 1-frequent sets, and gradually finding high-order frequent sets.Known theorem: If the item set X is a frequent set, then its non-empty subsets are all frequent sets.
It can be obtained from the theorem that, given a k-frequent set item set X, all k-1 subsets of X are frequent sets, that is to say, two k-1 frequent itemsets can be found, they Only one item is different, and it is equal to X when connected. This proves that the k-candidate set generated by concatenating the k-1 frequent set covers the k-frequent set. At the same time, if the item set Y in the k-candidate set contains a certain k-1 subset that does not belong to the k-1 frequent set, then Y cannot be a frequent set and should be cut from the candidate set. This is one of the core ideas of the Apriori algorithm.
Most of the association rules are not causal, it shows the correlation between the two. Therefore, in this article, the process of studying the impact of the four performance evaluation independent variables on the three dependent variables uses correlation analysis. The forerunner of its association rules are performance evaluation indicators, which specifically include evaluation scores, number of projects, working hours, and work errors, and the subsequent ones are whether to stay, whether to be promoted, and employee level.
3.2. Basic flow of association algorithm
When the transaction database D is scanned for the first time, a 1-frequent set is generated. On this basis, 2-frequent sets are generated through connection and pruning. And so on, until no more frequent sets can be generated. In the kth cycle, that is, when k-frequent sets are generated, k-candidate sets are first generated. Each item set in the k-candidate set is for two items that are different from each other and belong to k-1 frequent sets. The k-candidate set is screened to produce k-frequent sets.
3.3. Analysis of the importance of random forest algorithm
The random forest function package can be used to analyze the importance of variables. There are 4 methods for measuring the importance of variables: importance score, importance() function, average precision reduction and Gini index. In the function package randomForest in the R language, there is a parameter that evaluates the importance of variables, importance, which can analyze the importance of the data variables used in the modeling process.
In random forest, the main principles of analyzing the importance of variables are:
(1) For each random tree in the random forest model, OOB data is used when calculating its data error outside the bag, which is recorded as Oe1;
(2) Randomly add noise perturbation to the feature P of all samples in the out-of-bag data, so that the value of the sample at P can be changed randomly, and then calculate its out-of-bag data error and record it as Oe2;
(3) Suppose there are M trees in the random forest, then the importance of the feature P = Ʃ(Oe2-Oe1)/M.
4. Algorithm implementation
4.1. Association algorithm implementation
The algorithm of the association rule analysis part is divided into three parts in total, which are the performance evaluation score, the number of projects involved, the average monthly working hours, and whether there is work negligence. These four factors (hereinafter referred to as the 4 factors) affect the level of employees, whether to stay, Whether the impact of promotion.
Analysis of the influence of 4 factors on whether employees will stay in office:
ji_xiao_raw is the preprocessed data set. The output on the right side of the rule is whether to stay left=0 and left=1. The left side includes last_evaluation, number_project, average_montly_hours, work_accident four attributes, set the maximum support to 0.005, confidence For 0.8, sort the rules and eliminate redundant rules.
The analysis of the influence of 4 factors on employee rank and whether it is appreciated is similar to the above-mentioned code flow, using the same association rules and eliminating redundant rules to analyze it.
4.2. Implementation of Random Forest Importance Analysis Algorithm
Random forest can give the effect of each independent variable on the dependent variable, and rank the importance of the independent variable. Run a random forest, 4 factors as independent variables, make the importance of independent variables to whether to stay.
Similarly, the analysis code for the importance of the 4 factors to the level of employees and whether they are appreciated is the same as the above, so I will not repeat them here.

